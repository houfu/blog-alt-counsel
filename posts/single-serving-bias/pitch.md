# Pitch: The Single-Serving Software Uncertainty

**Working Title**: "The Single-Serving Software Uncertainty: Why We Need Permission to Experiment"

In 2024, I wrote a 3-page prompt to generate one M&A term sheet and felt wasteful—but I also couldn't answer whether it would've actually served a client better than a standard template. I've created custom tables to present findings instead of traditional memos, felt great about the work, but got neutral client responses. The real tension isn't that I think in abstractions—it's that I genuinely don't know if bespoke work serves clients better, and that uncertainty makes the time investment feel illegitimate. Sam Harden's "Legal UI Revolution" reframed everything: when AI drops creation cost to 30 minutes, you can AFFORD to experiment. We're also underutilizing what AI can now do—using it for text generation (prompts, memos, documents) but not interactive decision tools, custom visualizations, or matter-specific demos. In 2026, I'm resolving to build single-serving legal software for regular clients and matters: custom interactive tools that might work better than templates—and explicitly ask clients which they prefer. The 30-minute threshold isn't just about efficiency; it's permission to experiment without needing certainty in advance.

## Key Elements

**Personal Hook**: The 3-page prompt competition story (felt wasteful, but couldn't validate whether it would've served better)

**Real-World Example**: Custom tables for client presentations - felt great, got neutral response, still don't know if it mattered

**Core Insight**: The real tension is uncertainty - we genuinely don't know if bespoke work serves clients better, and that makes time investment feel illegitimate

**The Permission Shift**: When creation cost = 30 minutes, you can AFFORD to experiment without needing proof in advance

**Capability Gap**: AI can now build interactive tools, visualizations, custom demos - but we're still mostly using it for text

**Explicit Feedback Loop**: Build tools AND ask clients which they prefer - run experiments, not declare best practices

**2026 Resolution**: Build single-serving legal software and explicitly track which clients find them valuable vs. which prefer templates

## Improvements Needed (Based on Reviewer Feedback)

**Concrete Examples Required:**
- Show one tool built start to finish (problem → 30-minute creation → client response → what learned)
- Specific tools/platforms (Claude? Cursor? Replit?)
- Learning curve for non-technical lawyers

**Address Failure Modes:**
- What if clients consistently prefer templates?
- What if experiment takes longer than expected?
- How do you know when to stop?

**Practical Implementation:**
- How to bill experimentation time
- What the "explicitly ask clients" conversation looks like
- Security/compliance concerns with AI tools
- IT department restrictions

**Measurement Framework:**
- How to collect client feedback systematically
- What questions to ask
- How to track which approaches work

## References

- Sam Harden's "The Legal UI Revolution" (https://getmatter.com/email/57365556/?token=57365556%3A8tUKznEjWxpXoVqEE_MIXFuQEHB-sJ3u1RBcFXDpaSE)
- User's prompt competition experience from 2024 (3-page M&A term sheet prompt)
- Custom table presentations for clients (neutral response)
- Connection to "Lawyers Got Prompt Engineering Wrong" article

## Target Audience

- Lawyers who code (primary)
- Legal technologists building tools
- Solo counsels and small legal teams with limited budgets
- Resource-constrained corporate lawyers who need permission to experiment
- Anyone struggling with "how do I justify time on experiments without proof they'll work?"

## Reviewer Consensus (2025-12-23)

Both legal-tech-blog-reviewer and inhouse-lawyer-reviewer strongly preferred this "uncertainty paradox" framing over the original "abstraction bias" approach:

**Why This Works Better:**
- Brutal honesty about measurement problem resonates
- "Permission to experiment" addresses the real barrier (can't justify time without proof)
- Creates space for community to share experiments (success AND failure)
- Meets readers where they are (uncertain, risk-averse) vs. diagnosing a cognitive bias
- Aligns with alt-counsel brand (honest assessments, practical solutions)

**Critical Success Factor (per corporate lawyer reviewer):**
"The article will sink or swim based on how actionable it is - concrete examples, realistic time/cost estimates, and honest discussion of failure modes."
